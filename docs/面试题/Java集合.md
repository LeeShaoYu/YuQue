
# Java集合

1. List和Set的区别？

   - List, Set 都是继承自 Collection 接口
   - List 特点：元素有放入顺序，元素可重复。Set 特点：元素无放入顺序，元素不可重复（注意：元素虽然无放入顺序，但是元素在 set 中的位置是有该元素的 HashCode 决定的，其位置其实是固定的）
   - List 接口有三个实现类：LinkedList，ArrayList，Vector。Set 接口有两个实现类：HashSet(底层由 HashMap 实现)，LinkedHashSet

2. List和Map的区别？

   - List 特点：元素有放入顺序，元素可重复;
   - Map 特点：元素按键值对存储，无放入顺序 ;
   - List 接口有三个实现类：LinkedList，ArrayList，Vector;
   - LinkedList：底层基于链表实现，链表内存是散乱的，每一个元素存储本身内存地址的同时还存储下一个元素的地址。链表增删快，查找慢;
   - Map 接口有三个实现类：HashMap，HashTable，LinkedHashMap
   - Map 相当于和 Collection 一个级别的；Map 集合存储键值对，且要求保持键的唯一性；

3. ArrayList 与 LinkedList 区别

   - ArrayList基于数组实现
   - LinkedList基于链表实现

4. ArrayList 与 Vector区别

   - 同步性：Vector 是线程安全的，也就是说是同步的 ，而 ArrayList 是线程不安全的，不是同步的。

   - 数据增长：当需要增长时，Vector 默认增长为原来一倍 ，而 ArrayList 却是原来的 50% ，这样 ArrayList 就有利于节约内存空间。

     说明：如果涉及到堆栈，队列等操作，应该考虑用 Vector，如果需要快速随机访问元素，应该使用 ArrayList

5. HashMap 和 HashTable 的区别

   - HashMap 几乎可以等价于 HashTable，除了 HashMap 是非 synchronized 的，并可以接受 null(HashMap 可以接受为 null 的键值 (key) 和值 (value)，而 HashTable 则不行)。
   - HashMap 是非 synchronized，而 HashTable 是 synchronized，这意味着 HashTable 是线程安全的，多个线程可以共享一个 HashTable；而如果没有正确的同步的话，多个线程是不能共享 HashMap 的。Java 5 提供了 ConcurrentHashMap，它是 HashTable 的替代，比 HashTable 的扩展性更好。
   - 另一个区别是 HashMap 的迭代器 (Iterator) 是 fail-fast 迭代器，而 HashTable 的 enumerator 迭代器不是 fail-fast 的。所以当有其它线程改变了 HashMap 的结构（增加或者移除元素），将会抛出 ConcurrentModificationException，但迭代器本身的 remove() 方法移除元素则不会抛出 ConcurrentModificationException 异常。但这并不是一个一定发生的行为，要看 JVM。这条同样也是 Enumeration 和 Iterator 的区别。
   - 由于 HashTable 是线程安全的也是 synchronized，所以在单线程环境下它比 HashMap 要慢。如果你不需要同步，只需要单一线程，那么使用 HashMap 性能要好过 HashTable。
   - HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。

6. HashSet 和 HashMap 区别

   | HashMap                                      | HashSet                                                      |
   | -------------------------------------------- | ------------------------------------------------------------ |
   | HashMap 实现了 Map 接口                      | HashSet 实现了 Set 接口                                      |
   | HashMap 储存键值对                           | HashSet 仅仅存储对象                                         |
   | 使用 put() 方法将元素放入 map 中             | 使用 add() 方法将元素放入 set 中                             |
   | HashMap 中使用键对象来计算 hashcode 值       | HashSet 使用成员对象来计算 hashcode 值，对于两个对象来说 hashcode 可能相同，所以 equals() 方法用来判断对象的相等性，如果两个对象不同的话，那么返回 false |
   | HashMap 比较快，因为是使用唯一的键来获取对象 | HashSet 较 HashMap 比较慢                                    |

7. ConcurrentHashMap和 HashMap 区别

   - 放入 HashMap 的元素是 key-value 对。
   - 底层说白了就是散列结构。
   - 要将元素放入到 HashMap 中，那么 key 的类型必须要实现 hashcode 方法，默认这个方法是根据对象的地址来计算的，接着还必须覆盖对象的 equals() 方法。
   - ConcurrentHashMap 对整个桶数组进行了分段，而 HashMap 则没有
   - ConcurrentHashMap 在每一个分段上都用锁进行保护，从而让锁的粒度更精细一些，并发性能更好，而 HashMap 没有锁机制，不是线程安全的

8. HashMap工作原理

   HashMap 基于 hashing 原理，我们通过 put() 和 get() 方法储存和获取对象。当我们将键值对传递给 put() 方法时，它调用键对象的 hashCode() 方法来计算 hashcode，让后找到 bucket 位置来储存值对象。当获取对象时，通过键对象的 equals() 方法找到正确的键值对，然后返回值对象。HashMap 使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap 在每个链表节点中储存键值对对象。

9. ConcurrentHashMap的工作原理

   ConcurrentHashMap 采用了非常精妙的"分段锁"策略，ConcurrentHashMap 的主干是个 Segment 数组。Segment 继承了 ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在 ConcurrentHashMap，一个 Segment 就是一个子哈希表，Segment 里维护了一个 HashEntry 数组，并发环境下，对于不同 Segment 的数据进行操作是不用考虑锁竞争的。



------



# Java线程

1. 创建线程的方式及实现

- 继承 Thread 类创建线程类
  - 定义 Thread 类的子类，并重写该类的 `run` 方法，该 `run` 方法的方法体就代表了线程要完成的任务。因此把 `run()` 方法称为执行体。
  - 创建 Thread 子类的实例，即创建了线程对象。
  - 调用线程对象的 `start()` 方法来启动该线程。

- 通过 Runnable 接口创建线程类
  - 定义 Runnable 接口的实现类，并重写该接口的 `run()` 方法，该 `run()` 方法的方法体同样是该线程的线程执行体。
  - 创建 Runnable 实现类的实例，并依此实例作为 Thread 的 target 来创建 Thread 对象，该 Thread 对象才是真正的线程对象。
  - 调用线程对象的 `start()` 方法来启动该线程。

- 通过 Callable 和 Future 创建线程
  - 创建 Callable 接口的实现类，并实现 `call()` 方法，该 `call()` 方法将作为线程执行体，并且有返回值。
  - 创建 Callable 实现类的实例，使用 FutureTask 类来包装 Callable 对象，该 FutureTask 对象封装了该 Callable 对象的 `call()` 方法的返回值。
  - 使用 FutureTask 对象作为 Thread 对象的 target 创建并启动新线程。
  - 调用 FutureTask 对象的 `get()` 方法来获得子线程执行结束后的返回值



2. sleep()、join（）、yield（）有什么区别

   - sleep()

     `sleep()` 方法需要指定等待的时间，它可以让当前正在执行的线程在指定的时间内暂停执行，进入阻塞状态，该方法既可以让其他同优先级或者高优先级的线程得到执行的机会，也可以让低优先级的线程得到执行机会。但是 `sleep()` 方法不会释放“锁标志”，也就是说如果有 `synchronized` 同步块，其他线程仍然不能访问共享数据。

   - wait()

     `wait()` 方法需要和 `notify()` 及 `notifyAll()` 两个方法一起介绍，这三个方法用于协调多个线程对共享数据的存取，所以必须在 `synchronized` 语句块内使用，也就是说，调用 `wait()`，`notify()` 和 `notifyAll()` 的任务在调用这些方法前必须拥有对象的锁。注意，它们都是 `Object` 类的方法，而不是 `Thread` 类的方法。

     `wait()` 方法与 `sleep()` 方法的不同之处在于，`wait()` 方法会释放对象的“锁标志”。当调用某一对象的 `wait()` 方法后，会使当前线程暂停执行，并将当前线程放入对象等待池中，直到调用了 `notify()` 方法后，将从对象等待池中移出任意一个线程并放入锁标志等待池中，只有锁标志等待池中的线程可以获取锁标志，它们随时准备争夺锁的拥有权。当调用了某个对象的 `notifyAll()` 方法，会将对象等待池中的所有线程都移动到该对象的锁标志等待池。

     除了使用 `notify()` 和 `notifyAll()` 方法，还可以使用带毫秒参数的 `wait(long timeout)` 方法，效果是在延迟 timeout 毫秒后，被暂停的线程将被恢复到锁标志等待池。

     此外，`wait()`，`notify()` 及 `notifyAll()` 只能在 `synchronized` 语句中使用，但是如果使用的是 `ReenTrantLock` 实现同步，该如何达到这三个方法的效果呢？解决方法是使用 `ReenTrantLock.newCondition()` 获取一个 `Condition` 类对象，然后 `Condition` 的 `await()`，`signal()` 以及 `signalAll()` 分别对应上面的三个方法。

   - yield()

     `yield()` 方法和 `sleep()` 方法类似，也不会释放“锁标志”，区别在于，它没有参数，即 `yield()` 方法只是使当前线程重新回到可执行状态，所以执行 `yield()` 的线程有可能在进入到可执行状态后马上又被执行，另外 `yield()` 方法只能使同优先级或者高优先级的线程得到执行机会，这也和 `sleep()` 方法不同。

   - join()

     `join()` 方法会使当前线程等待调用 `join()` 方法的线程结束后才能继续执行

3. ThreadLocal原理

   ThreadLocal 提供了线程本地变量，它可以保证访问到的变量属于当前线程，每个线程都保存有一个变量副本，每个线程的变量都不同。ThreadLocal 相当于提供了一种线程隔离，将变量与线程相绑定。

4. 线程池的实现原理

   当提交一个新任务到线程池时，线程池的处理流程如下：

   1. 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。
   2. 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。
   3. 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。

5. 线程池的几种方式和场景？

   在 `Executors` 类里面提供了一些静态工厂，生成一些常用的线程池。

   1. `newFixedThreadPool`：创建固定大小的线程池。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
   2. `newCachedThreadPool`：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能够创建的最大线程大小。
   3. `newSingleThreadExecutor`：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。
   4. `newScheduledThreadPool`：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。
   5. `newSingleThreadScheduledExecutor`：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。

6. 线程的生命周期

   新建(New)、就绪(Runnable)、运行(Running)、阻塞(Blocked)和死亡(Dead)5种状态

7. 





------



# Java锁

1. 说一说线程安全问题？

   在 Java 多线程编程当中，提供了多种实现 Java 线程安全的方式：

   - 最简单的方式，使用 `Synchronization` 关键字
   - 使用 `java.util.concurrent.atomic` 包中的原子类，例如 `AtomicInteger`
   - 使用 `java.util.concurrent.locks` 包中的锁
   - 使用线程安全的集合 `ConcurrentHashMap`
   - 使用 `volatile` 关键字，保证变量可见性（直接从内存读，而不是从线程 `cache` 读）

2. volatile实现原理？

   - 在 JVM 底层 volatile 是采用“内存屏障”来实现的
   - 缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量的副本是一致的。其核心思想如下：当某个 CPU 在写数据时，如果发现操作的变量是共享变量，则会通知其他 CPU 告知该变量的缓存行是无效的，因此其他 CPU 在读取该变量时，发现其无效会重新从主存中加载数据

3. synchronize实现原理？

   同步代码块是使用 `monitorenter` 和 `monitorexit` 指令实现的，同步方法（在这看不出来需要看 JVM 底层实现）依靠的是方法修饰符上的 `ACC_SYNCHRONIZED` 实现。

4. synchronized与lock的区别

   - synchronized 和 lock 的用法区别
     - synchronized(隐式锁)：在需要同步的对象中加入此控制，`synchronized` 可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。
     - lock（显示锁）：需要显示指定起始位置和终止位置。一般使用 `ReentrantLock` 类做为锁，多个线程中必须要使用一个 `ReentrantLock` 类做为对象才能保证锁的生效。且在加锁和解锁处需要通过 `lock()` 和 `unlock()` 显示指出。所以一般会在 `finally` 块中写 `unlock()` 以防死锁。
   - synchronized 和 lock 性能区别 `synchronized` 是托管给 JVM 执行的，而 `lock` 是 Java 写的控制锁的代码。在 **JDK 1.5** 中，`synchronize` 是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用 Java 提供的 `Lock` 对象，性能更高一些。但是到了 **JDK 1.6**，发生了变化。`synchronize` 在语义上很清晰，可以进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在 **JDK 1.6** 上 `synchronize` 的性能并不比 `Lock` 差。
   - synchronized 和 lock 机制区别
     - `synchronized` 原始采用的是 CPU 悲观锁机制，即线程获得的是独占锁。独占锁意味着其 他线程只能依靠阻塞来等待线程释放锁。
     - `Lock` 用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是 CAS 操作（Compare and Swap）。

5. CAS乐观锁

   CAS 是项乐观锁技术，当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。

   CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”这其实和乐观锁的冲突检查 + 数据更新的原理是一样的。

6. ABA问题

   CAS 会导致“ABA问题”。

   CAS 算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。

   比如说一个线程 one 从内存位置 V 中取出 A，这时候另一个线程 two 也从内存中取出 A，并且 two 进行了一些操作变成了 B，然后 two 又将 V 位置的数据变成 A，这时候线程 one 进行 CAS 操作发现内存中仍然是 A，然后 one 操作成功。尽管线程 one 的 CAS 操作成功，但是不代表这个过程就是没有问题的。

   部分乐观锁的实现是通过版本号（version）的方式来解决 ABA 问题，乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行 +1 操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现 ABA 问题，因为版本号只会增加不会减少

7. 乐观锁的业务场景及实现方式

   - 每次获取数据的时候，都不会担心数据被修改，所以每次获取数据的时候都不会进行加锁，但是在更新数据的时候需要判断该数据是否被别人修改过。如果数据被其他线程修改，则不进行数据更新，如果数据没有被其他线程修改，则进行数据更新。由于数据没有进行加锁，期间该数据可以被其他线程进行读写操作。
   - 比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。
   - 

------



# Spring

1. BeanFactory和ApplicationContext有什么区别？

   - BeanFactory 可以理解为含有 bean 集合的工厂类。BeanFactory 包含了种 bean 的定义，以便在接收到客户端请求时将对应的 bean 实例化。
   - BeanFactory 还能在实例化对象的时生成协作类之间的关系。此举将 bean 自身与 bean 客户端的配置中解放出来。BeanFactory 还包含了 bean 生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）。
   - 从表面上看，ApplicationContext 如同 BeanFactory 一样具有 bean 定义、bean 关联关系的设置，根据请求分发 bean 的功能。但 ApplicationContext 在此基础上还提供了其他的功能：
     - 提供了支持国际化的文本消息
     - 统一的资源文件读取方式
     - 已在监听器中注册的 bean 的事件

2. Spring Bean生命周期

   - Spring Bean 的生命周期简单易懂。在一个 bean 实例被初始化时，需要执行一系列的初始化操作以达到可用的状态。同样的，当一个 bean 不在被调用时需要进行相关的析构操作，并从 bean 容器中移除。
   - Spring bean factory 负责管理在 spring 容器中被创建的 bean 的生命周期。Bean 的生命周期由两组回调（call back）方法组成。
     - 初始化之后调用的回调方法。
     - 销毁之前调用的回调方法。
   - Spring 框架提供了以下四种方式来管理 bean 的生命周期事件：
     - InitializingBean 和 DisposableBean 回调接口
     - 针对特殊行为的其他 Aware 接口
     - Bean 配置文件中的 Custom init() 方法和 destroy() 方法
     - @PostConstruct 和 @PreDestroy 注解方式9

3. Spring IOC如何实现

   - Spring 中的 `org.springframework.beans` 包和 `org.springframework.context` 包构成了 Spring 框架 IoC 容器的基础。
   - BeanFactory 接口提供了一个先进的配置机制，使得任何类型的对象的配置成为可能。ApplicationContext 接口对 BeanFactory（是一个子接口）进行了扩展，在 BeanFactory 的基础上添加了其他功能，比如与 Spring 的 AOP 更容易集成，也提供了处理 message resource 的机制（用于国际化）、事件传播以及应用层的特别配置，比如针对 Web 应用的 WebApplicationContext。
   - `org.springframework.beans.factory.BeanFactory` 是 Spring IoC 容器的具体实现，用来包装和管理前面提到的各种 bean。BeanFactory 接口是 Spring IoC 容器的核心接口。

4. Springboot AOP是怎么一回事？

   面向切面编程，在我们的应用中，经常需要做一些事情，但是这些事情与核心业务无关，比如，要记录所有 update 方法的执行时间时间，操作人等等信息，记录到日志， 通过 Spring 的 AOP 技术，就可以在不修改 update 的代码的情况下完成该需求。

5. Spring AOP实现原理

   Spring AOP 中的动态代理主要有两种方式，**JDK 动态代理** 和 **CGLIB 动态代理**。JDK 动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK 动态代理的核心是 `InvocationHandler` 接口和 `Proxy` 类。

   如果目标类没有实现接口，那么 Spring AOP 会选择使用 CGLIB 来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB 是通过继承的方式做的动态代理，因此如果某个类被标记为 final，那么它是无法使用 CGLIB 做动态代理的。

6. 动态代理

   JDK 动态代理类和委托类需要都实现同一个接口。也就是说只有实现了某个接口的类可以使用 Java 动态代理机制。但是，事实上使用中并不是遇到的所有类都会给你实现一个接口。因此，对于没有实现接口的类，就不能使用该机制。而 CGLIB 则可以实现对类的动态代理。

7. Spring事务实现方式

   - 编程式事务

     所谓编程式事务指的是通过编码方式实现事务，即类似于 JDBC 编程实现事务管理。

   - 声明式事务管理方式

     声明式事务管理又有两种实现方式：

     - 基于 xml 配置文件的方式；
     - `@Transaction` 注解，将事务规则应用到业务逻辑中；

8. Spring事务底层原理

   - 划分处理单元 IOC

     由于 Spring 解决的问题是对单个数据库进行局部事务处理的，具体的实现首相用 Spring 中的 IOC 划分了事务处理单元。并且将对事务的各种配置放到了 IOC 容器中（设置事务管理器，设置事务的传播特性及隔离机制）。

     -AOP 拦截需要进行事务处理的类

     Spring 事务处理模块是通过 AOP 功能来实现声明式事务处理的，具体操作（比如事务实行的配置和读取，事务对象的抽象），用 `TransactionProxyFactoryBean` 接口来使用 AOP 功能，生成 proxy 代理对象，通过 `TransactionInterceptor` 完成对代理方法的拦截，将事务处理的功能编织到拦截的方法中。读取 IOC 容器事务配置属性，转化为 Spring 事务处理需要的内部数据结构（`TransactionAttributeSourceAdvisor`），转化为 `TransactionAttribute` 表示的数据对象。

   - 对事物处理实现（事务的生成、提交、回滚、挂起）

     Spring 委托给具体的事务处理器实现。实现了一个抽象和适配。适配的具体事务处理器：DataSource 数据源支持、Hibernate 数据源事务处理支持、JDO 数据源事务处理支持，JPA、JTA 数据源事务处理支持。这些支持都是通过设计 `PlatformTransactionManager`、`AbstractPlatforTransaction` 一系列事务处理的支持。 为常用数据源支持提供了一系列的 `TransactionManager`。

   - 结合

     `PlatformTransactionManager` 实现了 `TransactionInterception` 接口，让其与 `TransactionProxyFactoryBean` 结合起来，形成一个 Spring 声明式事务处理的设计体系。

9. 如何自定义注解

   1. 创建自定义注解和创建一个接口相似，但是注解的 `interface` 关键字需要以 `@` 符号开头。
   2. 注解方法不能带有参数；
   3. 注解方法返回值类型限定为：基本类型、String、Enums、Annotation 或者是这些类型的数组；
   4. 注解方法可以有默认值；
   5. 注解本身能够包含元注解，元注解被用来注解其它注解。

10. SpringMVC运行流程

    - Spring MVC 将所有的请求都提交给 `DispatcherServlet`，它会委托应用系统的其他模块负责对请求进行真正的处理工作。
    - `DispatcherServlet` 查询一个或多个 `HandlerMapping`，找到处理请求的 Controller.
    - `DispatcherServlet` 请求提交到目标 Controller
    - Controller 进行业务逻辑处理后，会返回一个 `ModelAndView`
    - Dispatcher 查询一个或多个 `ViewResolver` 视图解析器,找到 `ModelAndView` 对象指定的视图对象
    - 视图对象负责渲染返回给客户端。

11. SpringMVC运行流程

    在 `web.xml` 文件中给 Spring MVC 的 Servlet 配置了 `load-on-startup`，所以程序启动的时候会初始化 Spring MVC，在 `HttpServletBean` 中将配置的 `contextConfigLocation` 属性设置到 Servlet 中，然后在 `FrameworkServlet` 中创建了 `WebApplicationContext`，`DispatcherServlet` 根据 `contextConfigLocation` 配置的 `classpath` 下的 xml 文件初始化了 Spring MVC 总的组件。

12. Spring 的单例实现原理

    Spring 对 Bean 实例的创建是采用单例注册表的方式进行实现的，而这个注册表的缓存是 ConcurrentHashMap 对象。

13. Spring 框架中用到了哪些设计模式

    - 代理模式：在 AOP 和 Remoting 中被用的比较多。
    - 单例模式：在 Spring 配置文件中定义的 Bean 默认为单例模式。
    - 模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。
    - 前端控制器：Spring 提供了 DispatcherServlet 来对请求进行分发。
    - 视图帮助(View Helper )：Spring 提供了一系列的 JSP 标签，高效宏来辅助将分散的代码整合在视图里。
    - 依赖注入：贯穿于 BeanFactory / ApplicationContext 接口的核心理念。
    - 工厂模式：BeanFactory 用来创建对象的实例。

    

------



# 分布式

1. 分布式场景

   - 场景1：应用系统集群的 Session 共享

     应用系统集群最简单的就是服务器集群，比如：Tomcat 集群。应用系统集群的时候，比较凸显的问题是 Session 共享，Session 共享我们一是可以通过服务器插件来解决。另外一种也可以通过 Redis 等中间件实现。

   - 场景2：应用系统的服务化拆分

     服务化拆分，是目前非常火热的一种方式。现在都在提微服务。通过对传统项目进行服务化拆分，达到服务独立解耦，单服务又可以横向扩容。服务化拆分遇到的经典问题就是分布式事务问题。目前，比较常用的分布式事务解决方案有几种：消息最终一致性、TCC 补偿型事务等。

   - 场景3：底层数据库的压力分摊

     如果系统的性能压力出现在数据库，那我们就可以读写分离、分库分表等方案进行解决。

2. session分布式方案

   - 基于 nfs(net filesystem) 的 Session 共享
     将共享服务器目录 mount 各服务器的本地 session 目录，session 读写受共享服务器 io 限制，不能满足高并发。

   - 基于关系数据库的 Session 共享
     这种方案普遍使用。使用关系数据库存储 session 数据，对于 mysql 数据库，建议使用 heap 引擎。这种方案性能取决于数据库的性能，在高并发下容易造成表锁（虽然可以采用行锁的存储引擎，性能会下降），并且需要自己实现 session 过期淘汰机制。

   - 基于 Cookie 的 Session 共享
     这种方案也在大型互联网中普遍使用，将用户的 session 加密序列化后以 cookie 的方式保存在网站根域名下（比如 taobao.com），当用户访问所有二级域名站点式，浏览器会传递所有匹配的根域名的 cookie 信息，这样实现了用户 cookie 化 session 的多服务共享。此方案能够节省大量服务器资源，缺点是存储的信息长度受到 http 协议限制；cookie 的信息还需要做加密解密；请求任何资源时都会将 cookie 附加到 http 头上传到服务器，占用了一定带宽。

   - 基于 Web 容器的 Session 机制
     利用容器机制，通过配置即可实现。

   - 基于 Zookeeper 的分布式 Session 存储
   - 基于 Redis/Memcached 的 Session 共享存储
     这些 key/value 非关系存储有较高的性能，轻松达到 2000 左右的 qps，内置的过期机制正好满足 session 的自动实效特性。

3. 分布式锁的场景与实现

   - ZooKeeper锁

     - 获取锁
       1. 先有一个锁跟节点，lockRootNode，这可以是一个永久的节点
       2. 客户端获取锁，先在 lockRootNode 下创建一个顺序的瞬时节点，保证客户端断开连接，节点也自动删除
       3. 调用 lockRootNode 父节点的 getChildren() 方法，获取所有的节点，并从小到大排序，如果创建的最小的节点是当前节点，则返回 true,获取锁成功，否则，关注比自己序号小的节点的释放动作(exist watch)，这样可以保证每一个客户端只需要关注一个节点，不需要关注所有的节点，避免羊群效应。
       4. 如果有节点释放操作，重复步骤 3

     - 释放锁
       只需要删除步骤 2 中创建的节点即可

     使用 Zookeeper 的分布式锁存在什么样的优缺点呢？

     - 优点
       - 客户端如果出现宕机故障的话，锁可以马上释放
       - 可以实现阻塞式锁，通过 watcher 监听，实现起来也比较简单
       - 集群模式，稳定性比较高
     - 缺点
       - 一旦网络有任何的抖动，Zookeeper 就会认为客户端已经宕机，就会断掉连接，其他客户端就可以获取到锁。当然 Zookeeper 有重试机制，这个就比较依赖于其重试机制的策略了
       - 性能上不如缓存

   - Redis锁

4. 分布式事务

   - 分布式一致性

     **二阶提交协议（Two Phase Commitment Protocol）**、

     **三阶提交协议（Three Phase Commitment Protocol）** 

     **Paxos 算法**。

   - 分布式事务

     - 2PC

       **二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作**。

       所谓的两个阶段是指：第一阶段：**准备阶段(投票阶段)** 和第二阶段：**提交阶段（执行阶段）**。

     - 3PC

       与两阶段提交不同的是，三阶段提交有两个改动点。

       1. 引入超时机制。同时在协调者和参与者中都引入超时机制。
       2. 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

       也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 `CanCommit`、`PreCommit`、`DoCommit` 三个阶段

   - 两种区别

     相对于 2PC，3PC 主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行 commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。

5. 集群与负载均衡的算法与实现

   用户输入的流量通过负载均衡器按照某种负载均衡算法把流量均匀的分散到后端的多个服务器上，接收到请求的服务器可以独立的响应请求，达到负载分担的目的。从应用场景上来说，常见的负载均衡模型有全局负载均衡和集群内负载均衡，从产品形态角度来说，又可以分为硬件负载均衡和软件负载均衡。全局负载均衡一般通过DNS实现，通过将一个域名解析到不同VIP，来实现不同的region调度能力；硬件负载均衡器常见的有F5、A10、Array，它们的优缺点都比较明显，优点是功能强大，有专门的售后服务团队，性能比较好，缺点是缺少定制的灵活性，维护成本较高；现在的互联网更多的思路是通过软件负载均衡来实现，这样可以满足各种定制化需求，常见的软件负载均衡有 LVS、Nginx、Haproxy。

------



# 微服务

1. 前后端分离是怎么做的？

   在前后端分离架构中，后端只需要负责按照约定的数据格式向前端提供可调用的 API 服务即可。前后端之间通过 HTTP 请求进行交互，前端获取到数据后，进行页面的组装和渲染，最终返回给浏览器。

2. 如何解决跨域？

   **跨域**，指的是浏览器不能执行其他网站的脚本。它是由浏览器的同源策略（所谓同源是指，域名，协议，端口均相同）造成的，是浏览器对 JavaScript 施加的安全限制。

   - CORS(跨域资源共享)

     W3C标准。只要服务器实现了 CORS 接口，就可以跨源通信

   - JSONP

     只支持GET

3. 微服务有哪些框架？

   - SpringCloud
     - eureka
     - hystrix

   - SpringCloud-Alibaba
     - dubbo

4. 怎么理解RPC框架？

   RPC 是指远程过程调用，也就是说两台服务器 A，B 一个应用部署在 A 服务器上，想要调用 B 服务器上应用提供的函数或方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。 

   **RPC调用过程**

   1. 要解决通讯的问题 ，主要是通过在客户端和服务器之间建立 TCP 连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。
   2. 要解决寻址的问题，也就是说，A 服务器上的应用怎么告诉底层的 RPC 框架，如何连接到 B 服务器（如主机或 IP 地址）以及特定的端口，方法的名称是什么，这样才能完成调用。比如基于 Web 服务协议栈的 RPC，就要提供一个 endpoint URI，或者是从 UDDI 服务上查找。如果是 RMI 调用的话，还需要一个 RMI Registry 来注册服务的地址。
   3. 当 A 服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如 TCP 传递到 B 服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给 B 服务器。
   4. B 服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。
   5. 返回值还要发送回服务器 A 上的应用，也要经过序列化的方式发送，服务器 A 接到后，再反序列化，恢复为内存中的表达方式，交给 A 服务器上的应用。

5. 说说RPC的实现原理？

   首先需要有处理网络连接通讯的模块，负责连接建立、管理和消息的传输。其次需要有编解码的模块，因为网络通讯都是传输的字节码，需要将我们使用的对象序列化和反序列化。剩下的就是客户端和服务器端的部分，服务器端暴露要开放的服务接口，客户调用服务接口的一个代理实现，这个代理实现负责收集数据、编码并传输给服务器然后等待结果返回。

6. 说说Dubbo的实现原理

   Dubbo 作为 RPC 框架，实现的效果就是调用远程的方法就像在本地调用一样。如何做到呢？

   1. 本地有对远程方法的描述，包括方法名、参数、返回值，在 Dubbo 中是远程和本地使用同样的接口
   2. 要有对网络通信的封装，要对调用方来说通信细节是完全不可见的，网络通信要做的就是将调用方法的属性通过一定的协议（简单来说就是消息格式）传递到服务端
   3. 服务端按照协议解析出调用的信息；执行相应的方法；在将方法的返回值通过协议传递给客户端；客户端再解析；在调用方式上又可以分为同步调用和异步调用；

7. 怎么理解RESTful?

8. 怎么设计一个良好的API

   - GET：用于查询资源
   - POST：用于创建资源
   - PUT：用于更新服务端的资源的全部信息
   - PATCH：用于更新服务端的资源的部分信息
   - DELETE：用于删除服务端的资源。

9. 怎么理解RESTful API的幂等性？

   HTTP 幂等方法，是指无论调用多少次都不会有不同结果的 HTTP 方法。不管你调用一次，还是调用一百次，一千次，结果都是相同的。 

   - GET：幂等
   - POST：非幂等
   - PUT：幂等
   - PATCH：非幂等
   - DELETE：幂等

10. 如何保证接口的幂等性？

    token

    signature

11. 说说CAP定理，BASE理论？

    **CAP 理论**为：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。

    ![img](https://www.wangbase.com/blogimg/asset/201807/bg2018071607.jpg)

    - 一致性（Consistency）

      一致性指 “all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。

    - 可用性（Availability）

      可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。

    - 分区容错性（Partition tolerance）

      分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。

    **CAP 权衡**

    通过 CAP 理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？

    对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到 N 个 9，即保证 P 和 A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。

    对于涉及到钱财这样不能有一丝让步的场景，C 必须保证。网络发生故障宁可停止服务，这是保证 CA，舍弃 P。貌似这几年国内银行业发生了不下 10 起事故，但影响面不大，报到也不多，广大群众知道的少。还有一种是保证 CP，舍弃 A。例如网络故障是只读不写。

    孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。

    **BASE理论**

    eBay 的架构师 Dan Pritchett 源于对大规模分布式系统的实践总结，在 ACM 上发表文章提出 BASE 理论，BASE 理论是对 CAP 理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。

    - 基本可用（Basically Available）

      基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。

      电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。

    - 软状态（Soft State）

      软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication 的异步复制也是一种体现。

    - 最终一致性（Eventual Consistency）

      最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。

    **ACID 和 BASE 的区别**

    ACID 是传统数据库常用的设计理念，追求强一致性模型。BASE 支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。

    ACID 和 BASE 代表了两种截然相反的设计哲学，在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此 ACID 和 BASE 又会结合使用。

12. 怎么考虑数据一致性问题？

    - 两阶段提交 Two-Phase Commit (2PC)

      投票-决定

    - Try-Confirm/Cancel (TCC)

      TCC 也是补偿型事务模式，支持两阶段的商业模型

    - 

13. 谈谈最终一直性的实现方案？

14. 微服务与SOA的区别

    | 功能     | SOA                  | 微服务                       |
    | -------- | -------------------- | ---------------------------- |
    | 组件大小 | 大块业务逻辑         | 单独任务或小块业务逻辑       |
    | 耦合     | 通常松耦合           | 总是松耦合                   |
    | 公司架构 | 任何类型             | 小型、专注于功能交叉团队     |
    | 管理     | 着重中央管理         | 着重分散管理                 |
    | 目标     | 确保应用能够交互操作 | 执行新功能、快速拓展开发团队 |

15. 如何拆分服务

16. 微服务如何进行数据库管理？

17. 微服务的链式调用异常？

    一般情况下，每个微服务之间是独立的，如果某个服务宕机，只会影响到当前服务，而不会对整个业务系统产生影响。但是，服务端可能会在多个微服务之间产生一条链式调用，并把整合后的信息返回给客户端。在调用过程中，如果某个服务宕机或者网络不稳定可能造成整个请求失败。因此，为了应对微服务的链式调用异常，我们需要在设计微服务调用链时不宜过长，以免客户端长时间等待，以及中间环节出现错误造成整个请求失败。此外，可以考虑使用消息队列进行业务解耦，并且使用缓存避免微服务的链式调用从而提高该接口的可用性。

18. 怎么快速定位追踪问题？

    完善的异常处理，

    我们需要在记录日志时，标记出错误来源以及错误详情便于更好地分析与定位问题。

19. 微服务的安全问题？

    OAuth 是一个关于授权的开放网络标准，它允许第三方网站在用户授权的前提下访问用户在服务商那里存储的各种信息。实际上，OAuth 2.0 允许用户提供一个令牌给第三方网站，一个令牌对应一个特定的第三方网站，同时该令牌只能在特定的时间内访问特定的资源。用户在客户端使用用户名和密码在用户中心获得授权，然后客户端在访问应用是附上 Token 令牌。此时，应用接收到客户端的 Token 令牌到用户中心进行认证。

    一般情况下，access token 会添加到 HTTP Header 的 Authorization 参数中使用，其中经常使用到的是 Bearer Token 与 Mac Token。其中，Bearer Token 适用于安全的网络下 API 授权。MAC Token 适用于不安全的网络下 API 授权。

20. 

# 数据存储

1. MySql基本规范

   ##### 基础规范

   - 表存储引擎必须使用 InnoDB
   - 表字符集默认使用 utf8，必要时候使用 utf8mb4
     - 通用，无乱码风险，汉字 3 字节，英文 1 字节
     - utf8mb4 是 utf8 的超集，有存储 4 字节例如表情符号时，使用它
   - 禁止使用存储过程，视图，触发器，Event
     - 对数据库性能影响较大，互联网业务，能让站点层和服务层干的事情，不要交到数据库层
     - 调试，排错，迁移都比较困难，扩展性较差
   - 禁止在数据库中存储大文件，例如照片，可以将大文件存储在对象存储系统，数据库中存储路径
   - 禁止在线上环境做数据库压力测试
   - 测试，开发，线上数据库环境必须隔离

   ##### 命名规范

   - 库名，表名，列名必须用小写，采用下划线分隔
     - abc，Abc，ABC 都是给自己埋坑
   - 库名，表名，列名必须见名知义，长度不要超过 32 字符
     - tmp，wushan 谁 TM 知道这些库是干嘛的
   - 库备份必须以 bak 为前缀，以日期为后缀
   - 从库必须以 -s 为后缀
   - 备库必须以 -ss 为后缀

   ##### #表设计规范

   - 单实例表个数必须控制在 2000 个以内
   - 单表分表个数必须控制在 1024 个以内
   - 表必须有主键，推荐使用 UNSIGNED 整数为主键
     - 删除无主键的表，如果是 row 模式的主从架构，从库会挂住
   - 禁止使用外键，如果要保证完整性，应由应用程式实现
     - 外键使得表之间相互耦合，影响 update/delete 等 SQL 性能，有可能造成死锁，高并发情况下容易成为数据库瓶颈
   - 建议将大字段，访问频度低的字段拆分到单独的表中存储，分离冷热数据（具体参考：[《如何实施数据库垂直拆分》）](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959773&idx=1&sn=7e4ad0dcd050f6662dfaf39d9de36f2c&chksm=bd2d04018a5a8d17b92098b4840aac23982e32d179cdd957e4c55011f6a08f6bd31f9ba5cfee&scene=21#wechat_redirect)

   ##### #列设计规范

   - 根据业务区分使用 `tinyint/int/bigint`，分别会占用 `1/4/8` 字节

   - 根据业务区分使用`char/varchar`

     - 字段长度固定，或者长度近似的业务场景，适合使用 `char`，能够减少碎片，查询性能高
     - 字段长度相差较大，或者更新较少的业务场景，适合使用 `varchar`，能够减少空间

   - 根据业务区分使用`datetime/timestamp`

     - 前者占用 5 个字节，后者占用 4 个字节，存储年使用 `YEAR`，存储日期使用 `DATE`，存储时间使用 `datetime`

   - 必须把字段定义为`NOT NULL`并设默认值

     - NULL 的列使用索引，索引统计，值都更加复杂，MySQL 更难优化

- NULL 需要更多的存储空间

  - NULL 只能采用 `IS NULL` 或者 `IS NOT NULL` ，而在 `=/!=/in/not in` 时有大坑

  - 使用 `INT UNSIGNED` 存储 `IPv4` ，不要用 `char(15)`

  - 使用`
    varchar(20)
    `

    存储手机号，不要使用整数

    - 牵扯到国家代号，可能出现 `+/-/()` 等字符，例如 `+86`

- 手机号不会用来做数学运算

  - `varchar` 可以模糊查询，例如 `like‘138%’`

  - 使用`
    TINYINT
    ` 来代替`
    ENUM
    `

    - `ENUM` 增加新值要进行 `DDL` 操作

  ##### #索引规范

  - 唯一索引使用 `uniq_[字段名] `来命名_
  - _非唯一索引使用 idx_[字段名]来命名
  - 单张表索引数量建议控制在 5 个以内
  - 互联网高并发业务，太多索引会影响写性能
    - 生成执行计划时，如果索引太多，会降低性能，并可能导致 MySQL 选择不到最优索引
  - 异常复杂的查询需求，可以选择 ES 等更为适合的方式存储
   - 组合索引字段数不建议超过 5 个
  - 如果 5 个字段还不能极大缩小 row 范围，八成是设计有问题
   - 不建议在频繁更新的字段上建立索引
   - 非必要不要进行 JOIN 查询，如果要进行 JOIN 查询，被 JOIN 的字段必须类型相同，并建立索引
     - 踩过因为 JOIN 字段类型不一致，而导致全表扫描的坑么？

- 理解组合索引最左前缀原则，避免重复建设索引，如果建立了(a,b,c)，相当于建立了(a), (a,b), (a,b,c)

##### #SQL 规范

- 禁止使用 select *，只获取必要字段
  - select * 会增加 cpu/io/内存/带宽 的消耗
  - 指定字段能有效利用索引覆盖
  - 指定字段查询，在表结构变更时，能保证对应用程序无影响
- insert 必须指定字段，禁止使用 insert into T values()
  - 指定字段插入，在表结构变更时，能保证对应用程序无影响
- 隐式类型转换会使索引失效，导致全表扫描
  - 禁止在 where 条件列使用函数或者表达式
  - 导致不能命中索引，全表扫描
   - 禁止负向查询以及 % 开头的模糊查询
  - 导致不能命中索引，全表扫描
   - 禁止大表 JOIN 和子查询
     - 同一个字段上的 OR 必须改写问 IN，IN 的值必须少于 50 个
   - 应用程序必须捕获 SQL 异常
  - 方便定位线上问题

##### #说明

本军规适用于并发量大，数据量大的典型互联网业务，可直接带走参考，不谢。

2. MySql索引使用规范

   - 索引不会包含有 `NULL` 的列 只要列中包含有 `NULL` 值，都将不会被包含在索引中，复合索引中只要有一列含有 `NULL` 值，那么这一列对于此符合索引就是无效的。
   - 使用短索引 对串列进行索引，如果可以就应该指定一个前缀长度。例如，如果有一个 `char（255）` 的列，如果在前 `10` 个或 `20` 个字符内，多数值是唯一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和 `I/O` 操作。
   - 索引列排序 MySql 查询只使用一个索引，因此如果 `where` 子句中已经使用了索引的话，那么 `order by` 中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作，尽量不要包含多个列的排序，如果需要最好给这些列建复合索引。
   - `like` 语句操作 一般情况下不鼓励使用 `like` 操作，如果非使用不可，注意正确的使用方式。`like ‘%aaa%’` 不会使用索引，而 `like ‘aaa%’` 可以使用索引。
   - 不要在列上进行运算
   - 不使用 `NOT IN` 、`<>`、`！=`操作，但 `<` , `<=` ，`=` ，`>` , `>=` , `BETWEEN` , `IN` 是可以用到索引的
   - 索引要建立在经常进行select操作的字段上 这是因为，如果这些列很少用到，那么有无索引并不能明显改变查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。
   - 索引要建立在值比较唯一的字段上
   - 对于那些定义为 `text`、`image` 和 `bit` 数据类型的列不应该增加索引。因为这些列的数据量要么相当大，要么取值很少
   - 在 `where` 和 `join` 中出现的列需要建立索引
   - `where` 的查询条件里有不等号 `(where column != …)` , MySql 将无法使用索引
   - 如果 `where` 字句的查询条件里使用了函数(如：`where DAY(column)=…)`, MySql 将无法使用索引
   - 在 `join` 操作中(需要从多个数据表提取数据时)，MySql 只有在主键和外键的数据类型相同时才能使用索引，否则及时建立了索引也不会使用

3. 分库分表设计

   ##### 垂直分表

   ​	垂直分表在日常开发和设计中比较常见，通俗的说法叫做“大表拆小表”，拆分是基于关系型数据库中的“列”（字段）进行的。通常情况，某个表中的字段比较多，可以新建立一张“扩展表”，将不经常使用或者长度较大的字段拆分出去放到“扩展表”中。在字段很多的情况下，拆分开确实更便于开发和维护（笔者曾见过某个遗留系统中，一个大表中包含100多列的）。某种意义上也能避免“跨页”的问题（MySQL、MSSQL底层都是通过“数据页”来存储的，“跨页”问题可能会造成额外的性能开销，拆分字段的操作建议在数据库设计阶段就做好。如果是在发展过程中拆分，则需要改写以前的查询语句，会额外带来一定的成本和风险，建议谨慎。

   ##### 垂直分库

   ​	垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。系统层面的“服务化”拆分操作，能够解决业务系统层面的耦合和性能瓶颈，有利于系统的扩展维护。而数据库层面的拆分，道理也是相通的。与服务的“治理”和“降级”机制类似，我们也能对不同业务类型的数据进行“分级”管理、维护、监控、扩展等。

   众所周知，数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈，是大型分布式系统中优化数据库架构的重要手段。

   ##### 水平分表

   水平分表也称为横向分表，比较容易理解，就是将表中不同的数据行按照一定规律分布到不同的数据库表中（这些表保存在同一个数据库中），这样来降低单表数据量，优化查询性能。最常见的方式就是通过主键或者时间等字段进行Hash和取模后拆分。水平分表，能够降低单表的数据量，一定程度上可以缓解查询性能瓶颈。但本质上这些表还保存在同一个库中，所以库级别还是会有IO瓶颈。所以，一般不建议采用这种做法。

   ##### 水平分库

   水平分库分表与上面讲到的水平分表的思想相同，唯一不同的就是将这些拆分出来的表保存在不同的数据中。这也是很多大型互联网公司所选择的做法。某种意义上来讲，有些系统中使用的“冷热数据分离”（将一些使用较少的历史数据迁移到其他的数据库中。而在业务功能上，通常默认只提供热点数据的查询），也是类似的实践。在高并发和海量数据的场景下，分库分表能够有效缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源的瓶颈。当然，投入的硬件成本也会更高。同时，这也会带来一些复杂的技术问题和挑战（例如：跨分片的复杂查询，跨分片事务等）

4. SQL优化

   - 如果明确知道只有一条结果返回，`limit 1` 能够提高效率
   - 把计算放到业务层而不是数据库层，除了节省数据的 CPU，还有意想不到的查询缓存优化效果

5. MySql死锁问题

   产生死锁的四个必要条件：

   - 互斥条件：一个资源每次只能被一个进程使用。
   - 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
   - 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
   - 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

   这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 下列方法有助于最大限度地降低死锁：

   - 按同一顺序访问对象。
   - 避免事务中的用户交互。
   - 保持事务简短并在一个批处理中。
   - 使用低隔离级别。
   - 使用绑定连接。

6. MySql存储引擎的区别

   1. InnoDB 不支持 `FULLTEXT` 类型的索引。
   2. InnoDB 中不保存表的具体行数，也就是说，执行 `select count() from table` 时，InnoDB 要扫描一遍整个表来计算有多少行，但是 MyISAM 只要简单的读出保存好的行数即可。注意的是，当 `count()` 语句包含 `where` 条件时，两种表的操作是一样的。
   3. 对于 `AUTO_INCREMENT` 类型的字段，InnoDB 中必须包含只有该字段的索引，但是在 MyISAM 表中，可以和其他字段一起建立联合索引。
   4. `DELETE FROM table` 时，InnoDB 不会重新建立表，而是一行一行的删除。
   5. `LOAD TABLE FROM MASTER` 操作对 InnoDB 是不起作用的，解决方法是首先把 InnoDB 表改成 MyISAM 表，导入数据后再改成 InnoDB 表，但是对于使用的额外的 InnoDB 特性(例如外键)的表不适用。

   另外，InnoDB 表的行锁也不是绝对的，假如在执行一个 SQL 语句时 MySQL 不能确定要扫描的范围，InnoDB 表同样会锁全表，例如 `update table set num=1 where name like “%aaa%”`

7. 数据库索引的原理

   数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用 **BTree** 及其变种 **B+Tree**。

8. 为什么要用B-Tree?

   一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘 I/O 的存取次数。

9. 聚集索引与非聚集索引的区别？

   - 聚集索引一个表只能有一个，而非聚集索引一个表可以存在多个
   - 聚集索引存储记录是物理上连续存在，而非聚集索引是逻辑上的连续，物理存储并不连续
   - 聚集索引：物理存储按照索引排序；聚集索引是一种索引组织形式，索引的键值逻辑顺序决定了表数据行的物理存储顺序
   - 非聚集索引：物理存储不按照索引排序；非聚集索引则就是普通索引了，仅仅只是对数据列创建相应的索引，不影响整个表的物理存储顺序.
   - 索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。

10. limit太大导致加载太慢怎么解决？

    MySQL 的性能低是因为数据库要去扫描 `N + M` 条记录，然后又要放弃之前 `N` 条记录，开销很大

    解决思路：

    - 前端加缓存，或者其他方式，减少落到库的查询操作，例如某些系统中数据在搜索引擎中有备份的，可以用 es 等进行搜索
    - 使用延迟关联，即先通用 limit 得到需要数据的索引字段，然后再通过原表和索引字段关联获得需要数据

    ```sql
    select a.* from a,(select id from table_1 where is_deleted='N' limit 100000,20) b where a.id = b.id
    ```

    - 从业务上实现，不分页如此多，例如只能分页前 100 页，后面的不允许再查了
    - 不使用 limit N,M, 而是使用 limit N，即将 offset 转化为 where 条件。

11. 分布式主键生成方案？

    - 数据库自增长序列或字段
    - UUID
    - **使用 UUID to Int64 的方法**
    - **Redis 生成 ID**
    - **Twitter 的 snowflake 算法**
    - **利用 zookeeper 生成唯一 ID**
    - MongoDB 的 ObjectId

12. 如何选择合适的数据存储方案？

    ##### 关系型数据库 MySQL

    MySQL 是一个最流行的关系型数据库，在互联网产品中应用比较广泛。一般情况下，MySQL 数据库是选择的第一方案，基本上有 80% ~ 90% 的场景都是基于 MySQL 数据库的。因为，需要关系型数据库进行管理，此外，业务存在许多事务性的操作，需要保证事务的强一致性。同时，可能还存在一些复杂的 SQL 的查询。值得注意的是，前期尽量减少表的联合查询，便于后期数据量增大的情况下，做数据库的分库分表。

    ##### 内存数据库 Redis

    随着数据量的增长，MySQL 已经满足不了大型互联网类应用的需求。因此，Redis 基于内存存储数据，可以极大的提高查询性能，对产品在架构上很好的补充。例如，为了提高服务端接口的访问速度，尽可能将读频率高的热点数据存放在 Redis 中。这个是非常典型的以空间换时间的策略，使用更多的内存换取 CPU 资源，通过增加系统的内存消耗，来加快程序的运行速度。

    在某些场景下，可以充分的利用 Redis 的特性，大大提高效率。这些场景包括缓存，会话缓存，时效性，访问频率，计数器，社交列表，记录用户判定信息，交集、并集和差集，热门列表与排行榜，最新动态等。

    使用 Redis 做缓存的时候，需要考虑数据不一致与脏读、缓存更新机制、缓存可用性、缓存服务降级、缓存穿透、缓存预热等缓存使用问题。

    ##### 文档数据库 MongoDB

    MongoDB 是对传统关系型数据库的补充，它非常适合高伸缩性的场景，它是可扩展性的表结构。基于这点，可以将预期范围内，表结构可能会不断扩展的 MySQL 表结构，通过 MongoDB 来存储，这就可以保证表结构的扩展性。

    此外，日志系统数据量特别大，如果用 MongoDB 数据库存储这些数据，利用分片集群支持海量数据，同时使用聚集分析和 MapReduce 的能力，是个很好的选择。

    MongoDB 还适合存储大尺寸的数据，GridFS 存储方案就是基于 MongoDB 的分布式文件存储系统。

    #### 列族数据库 HBase

    HBase 适合海量数据的存储与高性能实时查询，它是运行于 HDFS 文件系统之上，并且作为 MapReduce 分布式处理的目标数据库，以支撑离线分析型应用。在数据仓库、数据集市、商业智能等领域发挥了越来越多的作用，在数以千计的企业中支撑着大量的大数据分析场景的应用。

    ##### 全文搜索引擎 ElasticSearch

    在一般情况下，关系型数据库的模糊查询，都是通过 like 的方式进行查询。其中，like “value%” 可以使用索引，但是对于 like “%value%” 这样的方式，执行全表查询，这在数据量小的表，不存在性能问题，但是对于海量数据，全表扫描是非常可怕的事情。ElasticSearch 作为一个建立在全文搜索引擎 Apache Lucene 基础上的实时的分布式搜索和分析引擎，适用于处理实时搜索应用场景。此外，使用 ElasticSearch 全文搜索引擎，还可以支持多词条查询、匹配度与权重、自动联想、拼写纠错等高级功能。因此，可以使用 ElasticSearch 作为关系型数据库全文搜索的功能补充，将要进行全文搜索的数据缓存一份到 ElasticSearch 上，达到处理复杂的业务与提高查询速度的目的。

    ElasticSearch 不仅仅适用于搜索场景，还非常适合日志处理与分析的场景。**著名的 ELK 日志处理方案，由 ElasticSearch、LogStash 和 KibAna 三个组件组成**，包括了日志收集、聚合、多维度查询、可视化显示等。

13. MongoDB的使用场景？

    ##### 高伸缩性的场景

    MongoDB 非常适合高伸缩性的场景，它是可扩展性的表结构。基于这点，可以将预期范围内，表结构可能会不断扩展的 MySQL 表结构，通过 MongoDB 来存储，这就可以保证表结构的扩展性。

    ##### 日志系统的场景

    日志系统数据量特别大，如果用 MongoDB 数据库存储这些数据，利用分片集群支持海量数据，同时使用聚集分析和 MapReduce 的能力，是个很好的选择。

    ##### 分布式文件存储

    MongoDB 还适合存储大尺寸的数据，之前介绍的 GridFS 存储方案，就是基于 MongoDB 的分布式文件存储系统。

14. ObjectId规则

15. 倒排索引

    倒排索引（英语：Inverted index），也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。有两种不同的反向索引形式：

    - 一条记录的水平反向索引（或者反向档案索引）包含每个引用单词的文档的列表。
    - 一个单词的水平反向索引（或者完全反向索引）又包含每个单词在一个文档中的位置。

16. ElasticSearch使用场景

    - 全文搜索，这个是用的最多的。加上分词插件、拼音插件什么的可以做成强大的全文搜索引擎。
    - 数据库，挺奇葩的用法，因为 ES 存数相同数据，更费空间，不过确实不错，因为他的强大统计分析汇总能力，再加上分布式 P2P 扩展能力，现在硬件又那么便宜，所以就有人拿来当数据库了。
    - 在线统计分析引擎，日志系统，LogStash，不用解释了吧; 可以实时动态分析数据，很是爽。

    

# 缓存

1. Redis有哪些类型?

   - String：字符串
   - Hash：字典
   - List：列表
   - Set：集合
   - Sorted Set：有序集合

2. Redis内部结构？

   Redis 内部使用一个 redisObject 对象来表示所有的 key 和 value。

   - type ：代表一个 value 对象具体是何种数据类型。
   - encoding ：是不同数据类型在 redis 内部的存储方式，比如：type=string 代表 value 存储的是一个普通字符串，那么对应的 encoding 可以是 raw 或者是 int，如果是 int 则代表实际 redis 内部是按数值型类存储和表示这个字符串的，当然前提是这个字符串本身可以用数值表示，比如："123" "456"这样的字符串。
   - vm 字段：只有打开了 Redis 的虚拟内存功能，此字段才会真正的分配内存，该功能默认是关闭状态的。 Redis 使用 redisObject 来表示所有的 key/value 数据是比较浪费内存的，当然这些内存管理成本的付出主要也是为了给 Redis 不同数据类型提供一个统一的管理接口，实际作者也提供了多种方法帮助我们尽量节省内存使用。

3. Redis内存淘汰机制

   ##### 内存淘汰策略

   内存淘汰只是 Redis 提供的一个功能，为了更好地实现这个功能，必须为不同的应用场景提供不同的策略，内存淘汰策略讲的是为实现内存淘汰我们具体怎么做，要解决的问题包括淘汰键空间如何选择？在键空间中淘汰键如何选择？

   Redis 提供了下面几种淘汰策略供用户选择，其中默认的策略为 `noeviction` 策略：

   - noeviction：当内存使用达到阈值的时候，所有引起申请内存的命令会报错
   - allkeys-lru：在主键空间中，优先移除最近未使用的key
   - volatile-lru：在设置了过期时间的键空间中，优先移除最近未使用的 key
   - allkeys-random：在主键空间中，随机移除某个 key
   - volatile-random：在设置了过期时间的键空间中，随机移除某个 key
   - volatile-ttl：在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除

   这里补充一下主键空间和设置了过期时间的键空间，举个例子，假设我们有一批键存储在Redis中，则有那么一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间。设置了过期时间的键空间为主键空间的子集。

   ##### 怎么选择内存淘汰策略

   - allkeys-lru：如果我们的应用对缓存的访问符合幂律分布（也就是存在相对热点数据），或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择 allkeys-lru 策略
   - allkeys-random：如果我们的应用对于缓存 key 的访问概率相等，则可以使用这个策略
   - volatile-ttl：这种策略使得我们可以向 Redis 提示哪些 key 更适合被 eviction

   另外，`volatile-lru` 策略和 `volatile-random` 策略适合我们将一个Redis实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个 Redis 实例来达到相同的效果，值得一提的是将key设置过期时间实际上会消耗更多的内存，因此我们建议使用 `allkeys-lru` 策略从而更有效率的使用内存。

   

4. Redis使用场景

   - 缓存
   - 会话缓存
   - 时效性
   - 访问频率
   - 计数器
   - 社交列表
   - 记录用户判定信息
   - 交集、并集和差集
   - 热门列表与排行榜
   - 最新动态
   - 消息队列

5. Redis持久化机制

   #####  RDB（备份数据）

   RDB 持久化方式会在一个特定的间隔保存那个时间点的一个数据快照

   ##### AOF（备份命令）

   AOF 持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟 Redis 协议一致，以追加的方式进行保存

   Redis 的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。两种方式的持久化是可以同时存在的，但是当 Redis 重启时，AOF 文件会被优先用于重建数据。

6. Redis集群方案与实现

   - 客户端分片
   - 基于代理的分片
   - 路由查询
   - 客户端分片
   - 由客户端决定 key 写入或者读取的节点
   - 包括 Jedis 在内的一些客户端，实现了客户端分片机制

7. Redis为什么是单线程的？

   redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。

8. 缓存崩溃

   - 碰到这种情况，一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
   - 加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间 key 是锁着的，这时过来 1000 个请求 999 个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法。

9. 缓存降级

   ##### 页面降级

   在大促或者某些特殊情况下，某些页面占用了一些稀缺服务资源，在紧急情况下可以对其整个降级，以达到丢卒保帅；

   ##### #页面片段降级

   比如商品详情页中的商家部分因为数据错误了，此时需要对其进行降级；

   ##### #页面异步请求降级

   比如商品详情页上有推荐信息/配送至等异步加载的请求，如果这些信息响应慢或者后端服务有问题，可以进行降级；

   ##### #服务功能降级

   比如渲染商品详情页时需要调用一些不太重要的服务：相关分类、热销榜等，而这些服务在异常情况下直接不获取，即降级即可；

   ##### #读降级

   比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景；

   ##### #写降级

   比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。

   ##### #爬虫降级

   在大促活动时，可以将爬虫流量导向静态页或者返回空数据，从而保护后端稀缺资源。

   ##### #自动开关降级

   自动降级是根据系统负载、资源使用情况、SLA等指标进行降级。

   ##### #超时降级

   当访问的数据库/http服务/远程调用响应慢或者长时间响应慢，且该服务不是核心服务的话可以在超时后自动降级；比如商品详情页上有推荐内容/评价，但是推荐内容/评价暂时不展示对用户购物流程不会产生很大的影响；对于这种服务是可以超时降级的。如果是调用别人的远程服务，和对方定义一个服务响应最大时间，如果超时了则自动降级。

10. 缓存的合理性问题

    - 热点数据，缓存才有价值
    - 频繁修改的数据，看情况考虑使用缓存
    - 数据不一致性
    - 缓存更新机制
    - 缓存可用性
    - 缓存服务降级
    - 缓存预热
    - 缓存穿透





# 消息队列

1. 消息队列使用场景

   - 校验用户名等信息，如果没问题会在数据库中添加一个用户记录
   - 如果是用邮箱注册会给你发送一封注册成功的邮件，手机注册则会发送一条短信
   - 分析用户的个人信息，以便将来向他推荐一些志同道合的人，或向那些人推荐他
   - 发送给用户一个包含操作指南的系统通知

2. 消息的重发补充解决思路

   - 可靠消息服务定时查询状态为已发送并超时的消息
   - 可靠消息将消息重新投递到 MQ 组件中
   - 下游应用监听消息，在满足幂等性的条件下，重新执行业务。
   - 下游应用通知可靠消息服务该消息已经成功消费。
   - 通过消息状态确认和消息重发两个功能，可以确保上游应用、可靠消息服务和下游应用数据的最终一致性。

3. 消息的幂等性解决思路

   ##### 唯一索引，防止新增脏数据

   比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录

   ##### Token 机制

   防止页面重复提交

   ##### 悲观锁、乐观锁

   ##### 分布式锁

   ##### select + insert

   并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了

   注意：核心高并发流程不要用这种方法

4. 消息堆积的解决思路？

   ##### 增大批次

   瓶颈在消费吞吐量的时候，增加批次也可以改善性能

   ##### 增加线程数

   如果一些消费者组中的消费者线程还是有 1 个消费者线程消费多个分区的情况，建议增加消费者线程。尽量 1 个消费者线程对应 1 个分区，从而发挥现有分区数下的最大并行度。

5. 自己实现消息队列怎么做？

   大体上的设计是由一条线程 1 执行从等待列表中获取任务插入任务队列再由线程池中的线程从任务队列中取出任务去执行.

   添加一条线程 1 主要是防止在执行耗时的任务时阻塞主线程.当执行耗时任务时,添加的任务的操作快于取出任务的操作,

   当任务队列长度达到最大值时,线程 1 将被阻塞,等待线程 2,3... 从任务队列取出任务执行。

6. 如何保证消息的有序性？

   - 通过轮询所有队列的方式来确定消息被发送到哪一个队列（负载均衡策略）。订单号相同的消息会被先后发送到同一个队列中，
   - 在获取到路由信息以后，会根据算法来选择一个队列，同一个 OrderId 获取到的肯定是同一个队列。

   

   

   

   

   

# Netty

1. 为什么选择Netty

   - API 使用简单，开发门槛低；
   - 功能强大，预置了多种编解码功能，支持多种主流协议；
   - 定制能力强，可以通过 ChannelHandler 对通信框架进行灵活的扩展；
   - 性能高，通过与其它业界主流的 NIO 框架对比，Netty 的综合性能最优；
   - 成熟、稳定，Netty 修复了已经发现的所有 JDK NIO BUG，业务开发人员不需要再为 NIO 的 BUG 而烦恼；
   - 社区活跃，版本迭代周期短，发现的BUG可以被及时修复，同时，更多的新功能会被加入；
   - 经历了大规模的商业应用考验，质量已经得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它可以完全满足不同行业的商业应用。

   正是因为这些优点，Netty 逐渐成为 Java NIO 编程的首选框架。

2. 说说netty的使用场景

   - 构建高性能、低时延的各种 Java 中间件，例如 MQ、分布式服务框架、ESB 消息总线等，Netty 主要作为基础通信框架提供高性能、低时延的通信服务；
   - 公有或者私有协议栈的基础通信框架，例如可以基于 Netty 构建异步、高性能的 WebSocket 协议栈；
   - 各领域应用，例如大数据、游戏等，Netty 作为高性能的通信框架用于内部各模块的数据分发、传输和汇总等，实现模块之间高性能通信。

3. 什么是TCP粘包/拆包

   - 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包。
   - 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。
   - 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包。
   - 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

4. TCP粘包/拆包的解决办法

   - 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
   - 发送端将每个数据包封装为固定长度（不够的可以通过补 0 填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
   - 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。

5. Netty线程模型

   首先，Netty 使用 EventLoop 来处理连接上的读写事件，而一个连接上的所有请求都保证在一个 EventLoop 中被处理，一个 EventLoop 中只有一个 Thread，所以也就实现了一个连接上的所有事件只会在一个线程中被执行。一个 EventLoopGroup 包含多个 EventLoop，可以把一个 EventLoop 当做是 Reactor 线程模型中的一个线程，而一个 EventLoopGroup 类似于一个 ExecutorService

6. Netty的零拷贝

   “零拷贝”是指计算机操作的过程中，CPU 不需要为数据在内存之间的拷贝消耗资源。而它通常是指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间（User Space）而直接在内核空间（Kernel Space）中传输到网络的方式。

7. Netty内部执行流程

   - Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
   - Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。
   - Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

8. Netty重连实现

   - 心跳机制检测连接存活
   - 启动时连接重试
   - 运行中连接断开时重试

9. 

# 安全

1. 安全要素与STRIDE威胁

   ## STRIDE 威胁

   STRIDE 威胁，代表六种安全威胁：

   - 身份假冒（Spoofing）

     身份假冒，即伪装成某对象或某人。例如，我们通过伪造别人的 ID 进行操作

   - 篡改（Tampering）

     篡改，即未经授权修改数据或者代码。例如，我通过网络抓包或者某种途径修改某个请求包，而服务端没有进行进一步的防范措施，使得我篡改的请求包提交成功。

   - 抵赖（Repudiation）

     抵赖，即拒绝执行他人无法证实也无法反对的行为而产生抵赖。例如，我攻击了某个产品，他们并不知道是我做的，没有证据证明是我做的，我就可以进行抵赖，换句话说，我可以死不承认。

   - 信息泄露（Information Disclosure）

     信息泄露，即将信息暴露给未授权用户。例如，我通过某种途径获取未经加密的敏感信息，例如用户密码。

   - 拒绝服务（Denial of Service）

     拒绝服务，即拒绝或降低有效用户的服务级别。例如，我通过拒绝服务攻击，使得其他正常用户无法使用产品的相关服务功能。

   - 特权提升（Elevation of Privilege）

     特权提升，即通过非授权方式获得更高权限。例如，我试图用管理员的权限进行业务操作。

   为了防范上面的 STRIDE 威胁，我们需要采用一些防范措施：

   | 威胁     | 安全要素         | 消减技术                                 |
   | -------- | ---------------- | ---------------------------------------- |
   | 身份假冒 | 认证             | Kerberos、SSL/TLS、证书、认证码等        |
   | 篡改     | 完整性           | 访问控制列表、SSL/TLS、认证码等          |
   | 抵赖     | 非抵赖/审计/记录 | 安全审计和日志记录、数字签名、可信第三方 |
   | 信息泄露 | 保密             | 加密、访问控制列表                       |
   | 拒绝服务 | 可用性           | 访问控制列表、过滤、配额、授权           |
   | 特权提升 | 授权             | 访问控制列表、角色控制、授权             |

2. 常见的Web攻击

   #### SQL注入

   攻击者在 HTTP 请求中注入恶意的 SQL 代码，服务器使用参数构建数据库 SQL 命令时，恶意 SQL 被一起构造，并在数据库中执行。

   用户登录，输入用户名 Lusifer，密码 `'or '1' = '1'` ，如果此时使用参数构造的方式，就会出现

   ```sql
   select * from user where name = 'Lusifer' and password = '' or '1'='1'
   ```

   不管用户名和密码是什么内容，使查询出来的用户列表不为空。

   ##### 如何防范SQL注入

   使用预编译的 PrepareStatement 是必须的，但是一般我们会从两个方面同时入手：

   1. Web 端
      - 有效性检验。
      - 限制字符串输入的长度。
   2. 服务端
      - 不用拼接 SQL 字符串。
      - 使用预编译的 PrepareStatement。
      - 有效性检验。(为什么服务端还要做有效性检验？第一准则，外部都是不可信的，防止攻击者绕过 Web 端请求)
      - 过滤 SQL 需要的参数中的特殊字符。比如单引号、双引号。

   #### XSS 攻击

   跨站点脚本攻击，指攻击者通过篡改网页，嵌入恶意脚本程序，在用户浏览网页时，控制用户浏览器进行恶意操作的一种攻击方式。

   #### 如何防范 XSS 攻击

   1. 前端，服务端，同时需要字符串输入的长度限制。
   2. 前端，服务端，同时需要对HTML转义处理。将其中的 `<` ,`>` 等特殊字符进行转义编码。

   #### CSRF 攻击

   ##### 什么是 CSRF 攻击

   跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。可以这么理解 CSRF 攻击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF 能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。

   ##### 如何防范 CSRF 攻击

   1. 安全框架，例如 Spring Security。
   2. token 机制。在 HTTP 请求中进行 token 验证，如果请求中没有 token 或者 token 内容不正确，则认为 CSRF 攻击而拒绝该请求。
   3. 验证码。通常情况下，验证码能够很好的遏制 CSRF 攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。
   4. referer 识别。在 HTTP Header 中有一个字段 Referer，它记录了 HTTP 请求的来源地址。如果 Referer 是其他网站，就有可能是 CSRF 攻击，则拒绝该请求。但是，服务器并非都能取到 Referer。很多用户出于隐私保护的考虑，限制了 Referer 的发送。在某些情况下，浏览器也不会发送 Referer，例如 HTTPS 跳转到 HTTP。

   #### 文件上传漏洞

   ##### 什么是文件上传漏洞

   文件上传漏洞，指的是用户上传一个可执行的脚本文件，并通过此脚本文件获得了执行服务端命令的能力。

   许多第三方框架、服务，都曾经被爆出文件上传漏洞，比如很早之前的 Struts2，以及富文本编辑器等等，可能被一旦被攻击者上传恶意代码，有可能服务端就被人黑了。

   ##### 如何防范文件上传漏洞

   1. 文件上传的目录设置为不可执行。
   2. 判断文件类型。在判断文件类型的时候，可以结合使用 `MIME Type`，后缀检查等方式。因为对于上传文件，不能简单地通过后缀名称来判断文件的类型，因为攻击者可以将可执行文件的后缀名称改为图片或其他后缀类型，诱导用户执行。
   3. 对上传的文件类型进行白名单校验，只允许上传可靠类型。
   4. 上传的文件需要进行重新命名，使攻击者无法猜想上传文件的访问路径，将极大地增加攻击成本，同时向 `shell`, `php`, `rar`, `ara` 这种文件，因为重命名而无法成功实施攻击。
   5. 限制上传文件的大小。
   6. 单独设置文件服务器的域名。

   #### 访问控制

   一般来说，“基于 URL 的访问控制”是最常见的。

   ##### 垂直权限管理

   ​	访问控制实际上是建立用户与权限之间的对应关系，即“基于角色的访问控制”，RBAC。不同角色的权限有高低之分。高权限角色访问低权限角色的资源往往是被允许的，而低权限角色访问高权限的资源往往被禁止的。在配置权限时，应当使用“最小权限原则”，并使用“默认拒绝”的策略，只对有需要的主体单独配置”允许”的策略，这在很多时候能够避免发生“越权访问”。

   例如，Spring Security， Apache Shiro 都可以建立垂直权限管理。

   ### 水平权限管理

   ​	水平权限问题在同一个角色上，系统只验证了访问数据的角色，没有对角色内的用户做细分，由于水平权限管理是系统缺乏一个数据级的访问控制所造成的，因此水平权限管理又可以称之为“基于数据的访问控制”。

   ​	举个例子，比如我们之前的一个助手产品，客户端用户删除评论功能，如果没有做水平权限管理，即设置只有本人才可以删除自己的评论，那么用户通过修改评论id就可以删除别人的评论这个就存在危险的越权操作。

   这个层面，基本需要我们业务层面去处理，但是这个也是最为经常遗落的安全点。

   

3. 服务端通信安全攻防

   服务端接口通信过程中，一般是明文传输的，没有经过任何安全处理。那么这个时候就很容易在传输过程中被中间者窃听、篡改、冒充等风险。因此，对于敏感信息，以及重要文件就需要进行加密策略，保证通信的安全性。

   - Base64 加密传输

     Base64 是网络上最常见的用于传输 8Bit 字节代码的编码方式之一，但是它其实并不是一种用于安全领域的加密解密算法。

   - DES 对称加密

   - AES 对称加密

   - HTTPS

     - 内容加密，第三方无法窃听。
     - 身份认证，一旦被篡改，通信双方会立刻发现。
     - 数据完整性。防止内容冒充或者篡改。

   - URL 签名

     基于 OAuth2 协议，进行 URL 签名。

   - 双向 RSA 加密

     RSA 双向认证，就是用对方的公钥加密是为了保密，这个只有对方用私钥能解密。用自己的私钥加密是为了防抵赖，能用我的公钥解开，说明这是我发来的。

4. HTTPS原理解析

   HTTPS，简单的理解 HTTP 的安全版，即 HTTP 下加入 SSL 层，由两部分组成：HTTP + SSL / TLS。

   ![img](https://www.funtl.com/assets/HTTPS%E5%8E%9F%E7%90%86.png)

   - 用户在浏览器里输入一个 https 网址，此时客户端发起 HTTPS 请求，通过 TCP 和服务器建立连接（443端口）。
   - 服务器存放 CA 证书进行处理，注意的是采用 HTTPS 协议的服务器必须要有一套数字证书，这套证书其实就是一对公钥和私钥。
   - 服务器向客户端返回证书。证书里面包含了很多信息：比如域名，申请证书的公司，公钥等。
   - 客户端对证书进行解析。这部分工作是有客户端的 TLS 来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机数，然后用证书对该随机数进行加密。
   - 向服务器发送证书加密后的随机数。
   - 服务器用它的私钥进行解密，得到了客户端传过来的随机数。
   - 服务器用客户端的随机数加密后的信息发送给客户端。
   - 客户端用之前生成的密钥解密服务端传过来的信息。

   以上就是整个 HTTPS 的交互过程，大家是不是对整个流程有了比较大致的了解了呢。

   ##### HTTPS应用场景

   - 场景一，对 HTTPS 进行 CDN 加速
   - 对HTTPS 的域名通过 CNAME 绑定到另外一个 HTTPS 域名上

5. 授权与认证

   认证解决你是谁的问题 (who)，授权解决你能干什么的问题 (what)。

6. RBAC

   



# 性能

1. 性能指标

   - 响应时间

     用户感受软件系统为其服务所耗费的时间

   - 吞吐量

     软件系统在每单位时间内能处理多少个事务/请求/单位数据等。

   - 资源使用率

     CPU占用率、内存使用率、磁盘I/O、网络I/O等

   - 点击数

     点击数不是我们通常理解的用户鼠标点击次数，而是按照客户端向 Web Server 发起了多少次 http 请求计算的，一次鼠标可能触发多个 http 请求，这需要结合具体的 Web 系统实现来计算

   - 并发数

     并发用户数用来度量服务器并发容量和同步协调能力。

2. 性能瓶颈

   - 压测
     - Java Melody
     - Apache JMeter
     - Load Runner
     - 
   - 

3. 性能调优

   ##### 常用名词

   - TPS

     每秒钟处理完的事务次数，一般 TPS 是对整个系统来讲的。一个应用系统 1s 能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用 QPS 比较多。

   - QPS

     每秒钟处理完请求的次数；注意这里是处理完。具体是指发出请求到服务器处理完成功返回结果。可以理解在 Server 中有个 Counter，每处理一个请求加 1，1 秒后 Counter = QPS。

   - RT

     响应时间

   - 并发量

     同时处理的请求数

   

   

# 设计模式

# 需求分析



# 设计能力

1. 组件化

   #### 模块化与组件化

   首先来谈两个前端和移动端比较常见的词：`组件化` 和 `模块化`

   首先，可以肯定的是，组件化和模块化的中心思想都是 `分而治之`。目的都是将一个庞大的系统拆分成多个组件或者说是模块。

   ###### 组件化

   组件化就是基于可重用的目的，将一个大的软件系统按照分离关注点的形式，拆分成多个独立的组件，主要目的就是 **减少耦合**。

   ###### 模块化

   模块化的目的在于将一个程序按照其功能做拆分，分成相互独立的模块，以便于每个模块只包含与其功能相关的内容，模块之间通过接口调用。将一个大的系统模块化之后，每个模块都可以被高度复用。

   可以这样理解，

   - 模块化的目的是为了 `重用`，模块化后可以方便重复使用和插拨到不同的平台，不同的业务逻辑过程中。
   - 组件化的目的是为了 `解耦`，把系统拆分成多个组件，分离组件边界和责任，便于独立升级和维护。

2. 服务化

3. 领域建模

4. 领域边界

